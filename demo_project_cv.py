# -*- coding: utf-8 -*-
"""Demo_Project_CV.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O5E-_GNypwZLLvEQMLs3JPsbTWVF60zY

# Preparation

## Import Library
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import os
import time
from tensorflow.keras.preprocessing import image
from sklearn.metrics.pairwise import cosine_similarity
from google.colab import files
import pickle
import zipfile
from skimage.segmentation import mark_boundaries
import pandas as pd

"""## Load Data"""

zip_path = "/content/drive/MyDrive/Datasets/stanford_car_dataset_by_classes.zip"
extract_path = "/content/Dataset"

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
os.makedirs(extract_path, exist_ok=True)

# ‡πÅ‡∏ï‡∏Å‡πÑ‡∏ü‡∏•‡πå
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

DATASET_DIR = "/content/Dataset"

TEST_DIR = os.path.join(DATASET_DIR, "car_data", "car_data", "test")

SIZE_RESNET = 448
SIZE_EFFNET = 380
BATCH_SIZE = 16

temp_ds = tf.keras.utils.image_dataset_from_directory(
    TEST_DIR, image_size=(SIZE_RESNET, SIZE_RESNET), batch_size=1, shuffle=False
)
class_names = temp_ds.class_names
print(f"Loaded {len(class_names)} class names.")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Upload)
def load_and_preprocess_image(img_path, target_size):
    img = image.load_img(img_path, target_size=(target_size, target_size))
    img_array = image.img_to_array(img)
    img_expanded = np.expand_dims(img_array, axis=0)
    return img_expanded, img

"""## Load Model"""

resnet_path = '/content/drive/MyDrive/Model/FinalResnet_Final/models/resnet50_final_final_final.keras'
effnet_path = '/content/drive/MyDrive/Model/FinalEffnet_v2/models/effnet_best_final.keras'

resnet_model = tf.keras.models.load_model(resnet_path)

effnet_model = tf.keras.models.load_model(effnet_path)

print("Both Models Loaded Successfully!")

"""## Feature Extractor Setup"""

print("Building Feature Extractor from EfficientNetB4...")
feature_extractor = tf.keras.Model(
    inputs=effnet_model.input,
    outputs=effnet_model.layers[-2].output
)

"""## Building Similarity Database

### ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á database)
"""

SAVE_PATH = '/content/drive/MyDrive/Model/car_database.pkl' # ‡πÄ‡∏ã‡∏ü‡∏•‡∏á Drive
IMG_SIZE_EFFNET = 380

# --- Load Model & Feature Extractor ---
effnet_path = '/content/drive/MyDrive/Model/FinalEffnet_v2/models/effnet_best_final.keras'
model = tf.keras.models.load_model(effnet_path)

# ‡∏ï‡∏±‡∏î‡∏´‡∏±‡∏ß‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà Feature Vector
feature_extractor = tf.keras.Model(
    inputs=model.input,
    outputs=model.layers[-2].output
)

def load_and_preprocess_image(img_path, target_size):
    img = image.load_img(img_path, target_size=(target_size, target_size))
    img_array = image.img_to_array(img)
    img_expanded = np.expand_dims(img_array, axis=0)
    return img_expanded

# --- Loop ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Full Test Set) ---
print("Building Full Database (This may take 10-20 mins)...")
db_features = []
db_paths = []
db_labels = []

count = 0
for root, dirs, files in os.walk(TEST_DIR):
    for file in files:
        if file.lower().endswith(('.png', '.jpg', '.jpeg')):
            img_path = os.path.join(root, file)
            label_name = os.path.basename(root)

            try:
                # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ
                img_tensor = load_and_preprocess_image(img_path, IMG_SIZE_EFFNET)
                # 2. ‡∏î‡∏∂‡∏á Feature
                feat = feature_extractor.predict(img_tensor, verbose=0)

                # 3. ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                db_features.append(feat[0])
                db_paths.append(img_path)
                db_labels.append(label_name)

                count += 1
                if count % 100 == 0: print(f"Processed {count} images...")
            except Exception as e:
                print(f"Error processing {file}: {e}")

# --- Save ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå ---
print(f"Saving database to {SAVE_PATH}...")
with open(SAVE_PATH, 'wb') as f:
    pickle.dump({
        'features': np.array(db_features),
        'paths': db_paths,
        'labels': db_labels
    }, f)

"""## Load Database"""

DB_PATH = '/content/drive/MyDrive/Model/car_database.pkl'

print(f"Loading Car Database from: {DB_PATH}")

if os.path.exists(DB_PATH):
    with open(DB_PATH, 'rb') as f:
        data = pickle.load(f)

    database_features = data['features']
    database_paths = data['paths']
    database_labels = data['labels']

    print(f"Database Loaded! Found {len(database_features)} cars ready for search.")
else:
    print("‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô")

"""## Utility Function"""

def measure_inference_speed(model, img_tensor, iterations=10):
    # Warmup (‡∏£‡∏±‡∏ô‡πÄ‡∏•‡πà‡∏ô‡πÜ ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ GPU ‡∏ï‡∏∑‡πà‡∏ô)
    for _ in range(3):
        model.predict(img_tensor, verbose=0)

    # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏à‡∏£‡∏¥‡∏á
    start_time = time.time()
    for _ in range(iterations):
        model.predict(img_tensor, verbose=0)
    end_time = time.time()

    avg_time_ms = ((end_time - start_time) / iterations) * 1000
    return avg_time_ms

def make_gradcam_heatmap(img_tensor, full_model, backbone_name, conv_layer_name, pred_index=None):
    """
    Grad-CAM ‡πÅ‡∏ö‡∏ö Manual Forward Pass (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ KeyError/Graph Disconnect)
    1. ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô Backbone ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á Feature Map
    2. ‡∏£‡∏±‡∏ô‡∏™‡πà‡∏ß‡∏ô Head (Classifier) ‡∏ó‡∏µ‡∏•‡∏∞ Layer ‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
    """

    # 1. ‡∏î‡∏∂‡∏á Backbone (Inner Model) ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
    try:
        backbone = full_model.get_layer(backbone_name)
    except ValueError:
        print(f"‚ùå Error: ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ Backbone '{backbone_name}'")
        return np.zeros((img_tensor.shape[1], img_tensor.shape[2]))

    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô Backbone ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ 2 ‡∏≠‡∏¢‡πà‡∏≤‡∏á:
    #    a) Conv Output (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Heatmap)
    #    b) Backbone Output (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ Head)
    try:
        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤ Layer ‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô
        conv_output = backbone.get_layer(conv_layer_name).output
    except ValueError:
        print(f"‚ö†Ô∏è ‡∏´‡∏≤ Layer '{conv_layer_name}' ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏ô {backbone_name}")
        return np.zeros((img_tensor.shape[1], img_tensor.shape[2]))

    backbone_multi_output = tf.keras.models.Model(
        inputs=backbone.input,
        outputs=[conv_output, backbone.output]
    )

    # 3. ‡∏£‡∏∞‡∏ö‡∏∏ Layer ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏±‡∏ß (Head) ‡∏Ñ‡∏∑‡∏≠ Layer ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å Backbone
    head_layers = []
    found_backbone = False
    for layer in full_model.layers:
        if layer.name == backbone_name:
            found_backbone = True
            continue # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏ß backbone ‡πÑ‡∏õ
        if found_backbone:
            head_layers.append(layer)

    # 4. üßÆ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Gradients
    with tf.GradientTape() as tape:
        # 4.1 ‡∏£‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô Backbone
        conv_out, backbone_out = backbone_multi_output(img_tensor)

        # 4.2 ‡∏™‡∏±‡πà‡∏á Tape ‡πÉ‡∏´‡πâ‡∏à‡∏±‡∏ö‡∏ï‡∏≤‡∏î‡∏π Conv Output ‡πÑ‡∏ß‡πâ
        tape.watch(conv_out)

        # 4.3 ‡∏£‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô Head ‡∏ó‡∏µ‡∏•‡∏∞ Layer (Manual Forward Pass)
        x = backbone_out
        for layer in head_layers:
            x = layer(x) # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ layer ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á build model ‡πÉ‡∏´‡∏°‡πà

        preds = x

        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    # 5. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Gradient ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap
    grads = tape.gradient(class_channel, conv_out)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_out = conv_out[0]
    heatmap = conv_out @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô Heatmap ‡∏•‡∏á‡∏ö‡∏ô‡∏£‡∏π‡∏õ‡∏à‡∏£‡∏¥‡∏á
from PIL import Image # ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ PIL.Image ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Resize ‡πÅ‡∏ö‡∏ö‡∏û‡∏¥‡πÄ‡∏®‡∏©

def overlay_heatmap_sharper(heatmap, original_img_array, alpha=0.4, threshold=0.3, sharpness_mode='lanczos'):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏°‡∏ä‡∏±‡∏î‡∏Ç‡∏∂‡πâ‡∏ô (Sharper Grad-CAM)
    - threshold (0.0 - 1.0): ‡∏ï‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏õ‡πÄ‡∏•‡∏¢ (‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î noise)
    - sharpness_mode: 'lanczos' (‡∏Ñ‡∏°‡πÅ‡∏ö‡∏ö‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô), 'nearest' (‡∏Ñ‡∏°‡πÅ‡∏ö‡∏ö pixelated)
    """
    # 1. Thresholding: ‡∏ï‡∏±‡∏î noise ‡∏ó‡∏¥‡πâ‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏à‡∏∏‡∏î‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡πÄ‡∏î‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô
    # (‡∏™‡∏£‡πâ‡∏≤‡∏á copy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö array ‡πÄ‡∏î‡∏¥‡∏°)
    heatmap_processed = heatmap.copy()
    heatmap_processed[heatmap_processed < threshold] = 0

    # Re-normalize ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏î threshold
    if np.max(heatmap_processed) > 0:
         heatmap_processed = heatmap_processed / np.max(heatmap_processed)

    # 2. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ (Colormap)
    heatmap_uint8 = np.uint8(255 * heatmap_processed)
    jet = cm.get_cmap("jet")
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap_uint8]

    # 3. Resize ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏°‡∏ä‡∏±‡∏î (The Magic Step!)
    jet_heatmap_img = image.array_to_img(jet_heatmap)

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏†‡∏≤‡∏û
    if sharpness_mode == 'nearest':
        # ‡πÅ‡∏ö‡∏ö Nearest Neighbor: ‡∏Ñ‡∏°‡∏Å‡∏£‡∏¥‡∏ö ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å‡πÜ ‡πÄ‡∏´‡πá‡∏ô‡∏ä‡∏±‡∏î‡∏ß‡πà‡∏≤ original ‡∏Ñ‡∏∑‡∏≠ 14x14
        resample_method = Image.NEAREST
    else:
        # ‡πÅ‡∏ö‡∏ö Lanczos (Default): ‡∏Ñ‡∏°‡∏ä‡∏±‡∏î‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ)
        resample_method = Image.LANCZOS

    jet_heatmap_img = jet_heatmap_img.resize(
        (original_img_array.shape[1], original_img_array.shape[0]),
        resample=resample_method
    )
    jet_heatmap_final = image.img_to_array(jet_heatmap_img)

    # 4. ‡∏ã‡πâ‡∏≠‡∏ô‡∏†‡∏≤‡∏û
    superimposed_img = jet_heatmap_final * alpha + original_img_array
    superimposed_img = image.array_to_img(superimposed_img)
    return superimposed_img

# ‡πÄ‡∏ä‡πá‡∏Ñ ResNet
print("--- ResNet Layers ---")
for layer in resnet_model.layers:
    print(f"L1: {layer.name}")
    if hasattr(layer, 'layers'): # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏™‡πâ‡πÉ‡∏ô
        for sub_layer in layer.layers[-5:]: # ‡∏î‡∏π 5 ‡∏ï‡∏±‡∏ß‡∏ó‡πâ‡∏≤‡∏¢
            print(f"   L2: {sub_layer.name}")

# ‡πÄ‡∏ä‡πá‡∏Ñ ResNet
print("--- EffNet Layers ---")
for layer in effnet_model.layers:
    print(f"L1: {layer.name}")
    if hasattr(layer, 'layers'): # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏™‡πâ‡πÉ‡∏ô
        for sub_layer in layer.layers[-5:]: # ‡∏î‡∏π 5 ‡∏ï‡∏±‡∏ß‡∏ó‡πâ‡∏≤‡∏¢
            print(f"   L2: {sub_layer.name}")

"""# Demo"""

from google.colab import files

# ==========================================
# üîß CONFIG
# ==========================================
RESNET_BACKBONE = 'resnet50'
RESNET_INNER = 'conv5_block3_out'
EFFNET_BACKBONE = 'efficientnetb4'
EFFNET_INNER = 'top_activation'
THRESHOLD = 0.5 # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°‡∏Ç‡∏≠‡∏á Heatmap
# ==========================================

print("üöÄ Upload an image to analyze...")
uploaded = files.upload()

for fn in uploaded.keys():
    img_path = fn
    print(f"\nAnalyzing: {fn} ...")

    # --- 1. Prepare Images ---
    img_448, orig_448 = load_and_preprocess_image(img_path, SIZE_RESNET)
    img_380, orig_380 = load_and_preprocess_image(img_path, SIZE_EFFNET)

    # --- 2. Predictions & Speed ---
    # ResNet
    speed_res = measure_inference_speed(resnet_model, img_448, iterations=3)
    pred_res_raw = resnet_model.predict(img_448, verbose=0)
    idx_res = np.argmax(pred_res_raw)
    conf_res = np.max(pred_res_raw) * 100
    res_name = class_names[idx_res]
    # (Get Top 3 ResNet)
    top3_idx_res = pred_res_raw[0].argsort()[-3:][::-1]
    top3_res = [(class_names[i], pred_res_raw[0][i]*100) for i in top3_idx_res]

    # EffNet
    speed_eff = measure_inference_speed(effnet_model, img_380, iterations=3)
    pred_eff_raw = effnet_model.predict(img_380, verbose=0)
    idx_eff = np.argmax(pred_eff_raw)
    conf_eff = np.max(pred_eff_raw) * 100
    eff_name = class_names[idx_eff]
    # (Get Top 3 EffNet)
    top3_idx_eff = pred_eff_raw[0].argsort()[-3:][::-1]
    top3_eff = [(class_names[i], pred_eff_raw[0][i]*100) for i in top3_idx_eff]

    # --- 3. Check Ground Truth ---
    real_label = None
    for name in class_names:
        if name.lower().replace(" ", "") in fn.lower().replace(" ", ""):
            real_label = name
            break

    # Set Status Text/Color
    if real_label:
        col_res = 'green' if res_name == real_label else 'red'
        status_res = "Correct" if res_name == real_label else f"Wrong"

        col_eff = 'green' if eff_name == real_label else 'red'
        status_eff = "Correct" if eff_name == real_label else f"Wrong"

        truth_text = f"Ground Truth: {real_label}"
    else:
        col_res = 'black'; status_res = ""
        col_eff = 'black'; status_eff = ""
        truth_text = "Ground Truth: Unknown (Filename doesn't match)"

    # --- 4. Heatmaps (Manual Forward Pass - Robust) ---
    print("Generating Heatmaps...")
    hm_res = make_gradcam_heatmap(img_448, resnet_model, RESNET_BACKBONE, RESNET_INNER, idx_res)
    hm_eff = make_gradcam_heatmap(img_380, effnet_model, EFFNET_BACKBONE, EFFNET_INNER, idx_eff)

    vis_res = overlay_heatmap_sharper(hm_res, image.img_to_array(orig_448), threshold=THRESHOLD, sharpness_mode='lanczos')
    vis_eff = overlay_heatmap_sharper(hm_eff, image.img_to_array(orig_380), threshold=THRESHOLD, sharpness_mode='lanczos')

    # --- 5. Visualization ---
    plt.figure(figsize=(24, 8))

    # Plot 1: Original
    plt.subplot(1, 3, 1)
    plt.imshow(orig_380)
    plt.title(f"File: {fn}\n{truth_text}", fontsize=12)
    plt.axis('off')

    # Plot 2: ResNet
    plt.subplot(1, 3, 2)
    plt.imshow(vis_res)
    title_res = f"ResNet50\n{res_name}\nConf: {conf_res:.2f}% | {speed_res:.1f}ms"
    if status_res: title_res += f"\n{status_res}"
    plt.title(title_res, color=col_res, fontweight='bold', fontsize=12)
    plt.axis('off')
    # Show Top 3 as text in graph (optional) or just rely on print below
    plt.xlabel(f"Top 3:\n1. {top3_res[0][0]}\n2. {top3_res[1][0]}\n3. {top3_res[2][0]}", fontsize=10)

    # Plot 3: EffNet
    plt.subplot(1, 3, 3)
    plt.imshow(vis_eff)
    title_eff = f"EfficientNetB4\n{eff_name}\nConf: {conf_eff:.2f}% | {speed_eff:.1f}ms"
    if status_eff: title_eff += f"\n{status_eff}"
    plt.title(title_eff, color=col_eff, fontweight='bold', fontsize=12)
    plt.axis('off')
    plt.xlabel(f"Top 3:\n1. {top3_eff[0][0]}\n2. {top3_eff[1][0]}\n3. {top3_eff[2][0]}", fontsize=10)

    plt.tight_layout()
    plt.show()

    # --- Print Text Summary (‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÜ) ---
    print("-" * 60)
    print(f"üìä TOP 3 PREDICTIONS ANALYSIS")
    print("-" * 60)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ô‡∏ä‡∏±‡∏î‡πÜ
    df_compare = pd.DataFrame({
        'Rank': ['1st', '2nd', '3rd'],
        'ResNet Prediction': [f"{n} ({p:.1f}%)" for n, p in top3_res],
        'EffNet Prediction': [f"{n} ({p:.1f}%)" for n, p in top3_eff]
    })
    print(df_compare.to_string(index=False))
    print("-" * 60)

    # --- 6. Similarity Search ---
    print("\nüîé Finding visually similar cars (Database Search)...")
    if 'feature_extractor' not in globals():
         eff_inner = effnet_model.get_layer('efficientnetb4')
         feature_extractor = tf.keras.Model(inputs=eff_inner.inputs, outputs=eff_inner.output)

    curr_feat = feature_extractor.predict(img_380, verbose=0)
    sims = cosine_similarity(curr_feat, database_features)
    sorted_indices = sims[0].argsort()[::-1] # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô

    # --- üõ†Ô∏è Logic ‡πÉ‡∏´‡∏°‡πà: ‡∏´‡∏≤ 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏£‡∏∏‡πà‡∏ô‡∏Å‡∏±‡∏ô ---
    top_unique_indices = []
    seen_labels = set()

    # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏´‡∏≤‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏Ñ‡∏£‡∏ö 5 ‡∏Ñ‡∏±‡∏ô
    for idx in sorted_indices:
        label = database_labels[idx]

        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏° (‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥)
        if label in seen_labels:
            continue

        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
        seen_labels.add(label)
        top_unique_indices.append(idx)

        # ‡∏Ñ‡∏£‡∏ö 5 ‡∏Ñ‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏¢‡∏∏‡∏î
        if len(top_unique_indices) >= 5:
            break

    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡πâ Loop ‡∏Ç‡πâ‡∏≤‡∏á‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ
    top_indices = top_unique_indices

    plt.figure(figsize=(20, 4))
    plt.suptitle(f"Top 5 Visually Similar Cars (Unique Models)", y=1.05, fontsize=14)

    for i, idx in enumerate(top_indices):
        path = database_paths[idx]
        label = database_labels[idx]
        score = sims[0][idx] * 100
        try:
            sim_img = image.load_img(path, target_size=(300, 300))
            plt.subplot(1, 5, i+1)
            plt.imshow(sim_img)
            plt.title(f"{label}\nSim: {score:.1f}%", fontsize=10)
            plt.axis('off')
        except: pass
    plt.show()

"""## ‡∏™‡∏≥‡∏£‡∏≠‡∏á"""

print("\nüîé Finding visually similar cars (Database Search)...")
if 'feature_extractor' not in globals():
      eff_inner = effnet_model.get_layer('efficientnetb4')
      feature_extractor = tf.keras.Model(inputs=eff_inner.inputs, outputs=eff_inner.output)

curr_feat = feature_extractor.predict(img_380, verbose=0)
sims = cosine_similarity(curr_feat, database_features)
top_idxs = sims[0].argsort()[-6:-1][::-1]

plt.figure(figsize=(20, 4))
plt.suptitle(f"Top 5 Similar Cars found in Database", y=1.05, fontsize=14)

for i, idx in enumerate(top_idxs):
    path = database_paths[idx]
    label = database_labels[idx]
    score = sims[0][idx] * 100
    try:
        sim_img = image.load_img(path, target_size=(300, 300))
        plt.subplot(1, 5, i+1)
        plt.imshow(sim_img)
        plt.title(f"{label}\nSim: {score:.1f}%", fontsize=10)
        plt.axis('off')
    except: pass
plt.show()

# ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏î‡∏π
print("‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å (Copy ‡πÑ‡∏õ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢):")
for name in class_names[:50]: # ‡∏î‡∏π 20 ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏£‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    print(name)